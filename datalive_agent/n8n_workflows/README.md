# DataLive N8N Workflows

## üìã Descripci√≥n General

Este directorio contiene los workflows de N8N para el sistema DataLive. Los workflows est√°n dise√±ados para trabajar con la arquitectura RAG+KAG+CAG del proyecto.

## üîÑ Workflows Disponibles

### 1. DataLive - Ingestion Workflow (`datalive-ingestion-workflow.json`)

**Prop√≥sito**: Procesar e ingestar documentos en el sistema DataLive.

**Caracter√≠sticas**:
- ‚úÖ Webhook endpoint para ingesta manual (`/datalive/ingest`)
- ‚úÖ Validaci√≥n de entrada y tipos de archivo soportados
- ‚úÖ Chunking inteligente de documentos usando Recursive Character Text Splitter
- ‚úÖ Generaci√≥n de embeddings con Ollama (nomic-embed-text:v1.5)
- ‚úÖ Almacenamiento vectorial en Qdrant
- ‚úÖ Almacenamiento de metadatos en PostgreSQL
- ‚úÖ Extracci√≥n b√°sica de entidades (emails, URLs)
- ‚úÖ Respuesta estructurada con informaci√≥n del procesamiento

**Tipos de archivo soportados**:
- `txt` - Texto plano
- `pdf` - Documentos PDF
- `docx` - Documentos Word
- `md` - Markdown
- `csv` - Datos tabulares
- `json` - Datos estructurados

### 2. DataLive - Query Workflow (`datalive-query-workflow.json`)

**Prop√≥sito**: Procesar consultas y generar respuestas usando las estrategias RAG, KAG y CAG.

**Caracter√≠sticas**:
- ‚úÖ Webhook endpoint para consultas (`/datalive/query`)
- ‚úÖ Router inteligente de estrategias (auto, rag, kag, cag)
- ‚úÖ B√∫squeda vectorial en Qdrant (RAG)
- ‚úÖ Consultas a PostgreSQL para contexto temporal (CAG)
- ‚úÖ Preparaci√≥n para consultas de grafo en Neo4j (KAG)
- ‚úÖ S√≠ntesis de respuestas con LLM (phi3:medium)
- ‚úÖ Respuesta estructurada con fuentes y m√©tricas

**Estrategias de consulta**:
- `auto` - Selecci√≥n autom√°tica basada en el an√°lisis de la consulta
- `rag` - Retrieval Augmented Generation para consultas factuales
- `kag` - Knowledge Augmented Generation para relaciones
- `cag` - Contextual Augmented Generation para consultas temporales

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

1. **N8N instalado y funcionando**
2. **Servicios de DataLive activos**:
   - PostgreSQL
   - Qdrant
   - Ollama con modelos:
     - `phi3:medium`
     - `nomic-embed-text:v1.5`
   - Neo4j (para KAG completo)

### Importar Workflows

1. Acceder a N8N: http://localhost:5678
2. Ir a "Workflows" ‚Üí "Add workflow" ‚Üí "Import from file"
3. Seleccionar los archivos JSON de este directorio
4. Configurar las credenciales necesarias

### Configurar Credenciales

Los workflows requieren las siguientes credenciales en N8N:

1. **Ollama**:
   - Name: `Ollama`
   - Base URL: `http://ollama:11434`

2. **Qdrant**:
   - Name: `Qdrant`
   - URL: `http://qdrant:6333`

3. **PostgreSQL**:
   - Name: `PostgreSQL`
   - Host: `postgres`
   - Database: `datalive`
   - User: `datalive`
   - Password: (desde .env)

## üì° Uso de los Workflows

### Ingesta de Documentos

```bash
curl -X POST http://localhost:5678/webhook/datalive/ingest \
  -H "Content-Type: application/json" \
  -d '{
    "source_type": "txt",
    "source": "Este es el contenido del documento a ingestar...",
    "metadata": {
      "title": "Mi Documento",
      "author": "Usuario"
    }
  }'
```

### Realizar Consultas

```bash
curl -X POST http://localhost:5678/webhook/datalive/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "¬øQu√© dice el documento sobre X?",
    "strategy": "auto",
    "max_results": 5
  }'
```

## üîß Personalizaci√≥n

### Modificar el Chunking

En el nodo "Split Text into Chunks", puedes ajustar:
- Tama√±o de chunks (default: 1000 caracteres)
- Overlap (default: 200 caracteres)
- Separadores personalizados

### Cambiar Modelos de IA

1. **Embeddings**: Cambiar el modelo en "Generate Embeddings"
2. **LLM**: Cambiar el modelo en "LLM Synthesizer"

### A√±adir Nuevas Fuentes

Para a√±adir Google Drive, GitHub u otras fuentes:
1. A√±adir nodo trigger correspondiente
2. Conectarlo al nodo "Validate Input"
3. Adaptar la extracci√≥n seg√∫n el tipo de fuente

## üêõ Troubleshooting

### Error: "Webhook not found"
- Verificar que los workflows est√©n activos
- Comprobar que las URLs de webhook sean correctas

### Error: "Model not found"
- Verificar que Ollama tenga los modelos descargados:
  ```bash
  docker exec datalive-ollama ollama list
  ```

### Error: "Connection refused"
- Verificar que todos los servicios est√©n corriendo:
  ```bash
  docker-compose ps
  ```

## üìä M√©tricas y Monitoreo

Los workflows incluyen informaci√≥n de m√©tricas en las respuestas:
- `processing_time`: Tiempo de procesamiento en segundos
- `confidence`: Nivel de confianza de la respuesta
- `chunks`: N√∫mero de chunks procesados (ingesta)
- `sources`: Fuentes utilizadas para la respuesta

## üîí Seguridad

- Los webhooks deben protegerse con autenticaci√≥n en producci√≥n
- Validaci√≥n de entrada en todos los puntos de entrada
- Sanitizaci√≥n de contenido antes del procesamiento
- Logs de auditor√≠a para todas las operaciones

## ü§ù Contribuir

Para mejorar estos workflows:
1. Hacer fork del repositorio
2. Crear una rama para tu feature
3. Probar exhaustivamente los cambios
4. Crear un PR con descripci√≥n detallada