{
    "name": "Git Repository Ingestion",
    "nodes": [
      {
        "parameters": {
          "rule": {
            "interval": [
              {
                "field": "hours",
                "hoursInterval": 1
              }
            ]
          }
        },
        "id": "schedule-trigger",
        "name": "Schedule Trigger",
        "type": "n8n-nodes-base.scheduleTrigger",
        "typeVersion": 1.1,
        "position": [250, 300]
      },
      {
        "parameters": {
          "values": {
            "string": [
              {
                "name": "repositories",
                "value": "={{$env.GIT_REPOSITORIES}}"
              }
            ]
          }
        },
        "id": "set-repos",
        "name": "Set Repositories",
        "type": "n8n-nodes-base.set",
        "typeVersion": 3,
        "position": [450, 300]
      },
      {
        "parameters": {
          "fieldToSplitOut": "repositories",
          "splitOutValue": "={{$json.repositories.split(',')}}"
        },
        "id": "split-repos",
        "name": "Split Repositories",
        "type": "n8n-nodes-base.itemLists",
        "typeVersion": 3,
        "position": [650, 300]
      },
      {
        "parameters": {
          "command": "cd /tmp && git clone --depth 1 {{$json.repository}} repo_{{$itemIndex}} 2>&1 || (cd repo_{{$itemIndex}} && git pull origin main 2>&1)"
        },
        "id": "clone-repo",
        "name": "Clone/Pull Repository",
        "type": "n8n-nodes-base.executeCommand",
        "typeVersion": 1,
        "position": [850, 300]
      },
      {
        "parameters": {
          "command": "find /tmp/repo_{{$itemIndex}} -type f \\( -name '*.md' -o -name '*.txt' -o -name '*.yaml' -o -name '*.yml' -o -name '*.json' -o -name '*.tf' -o -name '*.py' -o -name '*.js' -o -name '*.ts' -o -name 'README*' -o -name 'LICENSE*' \\) -not -path '*/\\.*' -not -path '*/node_modules/*' -not -path '*/venv/*' | head -100"
        },
        "id": "find-files",
        "name": "Find Documentation Files",
        "type": "n8n-nodes-base.executeCommand",
        "typeVersion": 1,
        "position": [1050, 300]
      },
      {
        "parameters": {
          "jsCode": "// Parse file list and prepare for processing\nconst fileList = $input.first().json.stdout.trim().split('\\n').filter(f => f);\nconst repoUrl = $input.first().json.repository;\nconst repoName = repoUrl.split('/').pop().replace('.git', '');\n\nconst files = fileList.map(filePath => {\n  const relativePath = filePath.replace(`/tmp/repo_${$itemIndex}/`, '');\n  const fileName = filePath.split('/').pop();\n  const extension = fileName.split('.').pop();\n  \n  // Determine file type for specialized processing\n  let fileType = 'text';\n  if (['yaml', 'yml'].includes(extension)) fileType = 'yaml';\n  else if (extension === 'json') fileType = 'json';\n  else if (extension === 'tf') fileType = 'terraform';\n  else if (['py', 'js', 'ts'].includes(extension)) fileType = 'code';\n  else if (extension === 'md') fileType = 'markdown';\n  \n  return {\n    filePath,\n    relativePath,\n    fileName,\n    extension,\n    fileType,\n    repoName,\n    repoUrl,\n    sourceType: 'git',\n    sourceId: `${repoName}:${relativePath}`\n  };\n});\n\nreturn files;"
        },
        "id": "prepare-files",
        "name": "Prepare File Metadata",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [1250, 300]
      },
      {
        "parameters": {
          "batchSize": 10,
          "options": {}
        },
        "id": "batch-files",
        "name": "Batch Files",
        "type": "n8n-nodes-base.splitInBatches",
        "typeVersion": 3,
        "position": [1450, 300]
      },
      {
        "parameters": {
          "path": "={{$json.filePath}}",
          "options": {
            "encoding": "utf8"
          }
        },
        "id": "read-file",
        "name": "Read File Content",
        "type": "n8n-nodes-base.readBinaryFiles",
        "typeVersion": 1,
        "position": [1650, 300]
      },
      {
        "parameters": {
          "jsCode": "// Enhanced processing for different file types\nconst item = $input.first();\nconst content = item.binary.data.toString('utf8');\nconst metadata = item.json;\n\nlet processedContent = content;\nlet additionalMetadata = {};\n\n// Special processing based on file type\nswitch(metadata.fileType) {\n  case 'yaml':\n    // Extract YAML front matter or structure\n    try {\n      const yaml = require('js-yaml');\n      const parsed = yaml.load(content);\n      additionalMetadata.structure = Object.keys(parsed || {});\n    } catch (e) {\n      // Continue with raw content\n    }\n    break;\n    \n  case 'terraform':\n    // Extract resource types\n    const resourceMatches = content.match(/resource\\s+\"([^\"]+)\"/g) || [];\n    additionalMetadata.resources = resourceMatches.map(r => r.split('\"')[1]);\n    break;\n    \n  case 'code':\n    // Extract function/class definitions\n    const functionMatches = content.match(/(?:function|def|class)\\s+(\\w+)/g) || [];\n    additionalMetadata.definitions = functionMatches.map(f => f.split(/\\s+/)[1]);\n    break;\n    \n  case 'markdown':\n    // Extract headers for better chunking\n    const headers = content.match(/^#{1,6}\\s+.+$/gm) || [];\n    additionalMetadata.headers = headers;\n    break;\n}\n\n// Calculate hash for change detection\nconst crypto = require('crypto');\nconst contentHash = crypto.createHash('sha256').update(content).digest('hex');\n\nreturn {\n  ...metadata,\n  content: processedContent,\n  contentHash,\n  contentLength: content.length,\n  lineCount: content.split('\\n').length,\n  additionalMetadata,\n  lastModified: new Date().toISOString()\n};"
        },
        "id": "process-content",
        "name": "Process File Content",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [1850, 300]
      },
      {
        "parameters": {
          "method": "POST",
          "url": "={{$env.POSTGRES_HOST}}/rest/query",
          "authentication": "genericCredential",
          "genericAuthType": "httpBasicAuth",
          "sendBody": true,
          "bodyParameters": {
            "parameters": [
              {
                "name": "query",
                "value": "INSERT INTO rag.documents (source_id, source_type, file_name, file_path, document_hash, metadata) VALUES ('{{$json.sourceId}}', '{{$json.sourceType}}', '{{$json.fileName}}', '{{$json.relativePath}}', '{{$json.contentHash}}', '{{JSON.stringify($json.additionalMetadata)}}') ON CONFLICT (source_id, source_type) WHERE is_deleted = FALSE DO UPDATE SET document_hash = EXCLUDED.document_hash, updated_at = NOW() RETURNING document_id, (xmax = 0) as is_new"
              }
            ]
          }
        },
        "id": "upsert-document",
        "name": "Upsert Document",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.1,
        "position": [2050, 300],
        "credentials": {
          "httpBasicAuth": {
            "id": "{{POSTGRES_CREDENTIAL_ID}}"
          }
        }
      },
      {
        "parameters": {
          "conditions": {
            "boolean": [
              {
                "value1": "={{$json.is_new}}",
                "value2": true
              }
            ]
          }
        },
        "id": "check-if-new",
        "name": "Check if New/Modified",
        "type": "n8n-nodes-base.if",
        "typeVersion": 2,
        "position": [2250, 300]
      },
      {
        "parameters": {
          "jsCode": "// Smart chunking based on file type\nconst content = $input.first().json.content;\nconst fileType = $input.first().json.fileType;\nconst documentId = $input.first().json.document_id;\n\nlet chunks = [];\nconst maxChunkSize = 1000;\nconst overlap = 200;\n\nswitch(fileType) {\n  case 'markdown':\n    // Chunk by headers\n    const sections = content.split(/^#{1,3}\\s+/m);\n    sections.forEach((section, idx) => {\n      if (section.trim()) {\n        chunks.push({\n          content: section.trim(),\n          chunkIndex: idx,\n          chunkType: 'section'\n        });\n      }\n    });\n    break;\n    \n  case 'code':\n    // Chunk by functions/classes\n    const codeBlocks = content.split(/(?=(?:function|def|class)\\s+\\w+)/g);\n    codeBlocks.forEach((block, idx) => {\n      if (block.trim()) {\n        chunks.push({\n          content: block.trim(),\n          chunkIndex: idx,\n          chunkType: 'code_block'\n        });\n      }\n    });\n    break;\n    \n  default:\n    // Standard overlapping chunks\n    const lines = content.split('\\n');\n    let currentChunk = [];\n    let chunkIndex = 0;\n    \n    for (let i = 0; i < lines.length; i++) {\n      currentChunk.push(lines[i]);\n      \n      if (currentChunk.join('\\n').length > maxChunkSize) {\n        chunks.push({\n          content: currentChunk.join('\\n'),\n          chunkIndex: chunkIndex++,\n          chunkType: 'standard'\n        });\n        \n        // Keep last few lines for overlap\n        currentChunk = currentChunk.slice(-5);\n      }\n    }\n    \n    // Don't forget the last chunk\n    if (currentChunk.length > 0) {\n      chunks.push({\n        content: currentChunk.join('\\n'),\n        chunkIndex: chunkIndex,\n        chunkType: 'standard'\n      });\n    }\n}\n\n// Add document reference to each chunk\nreturn chunks.map(chunk => ({\n  ...chunk,\n  documentId,\n  ...$input.first().json\n}));"
        },
        "id": "chunk-content",
        "name": "Smart Chunking",
        "type": "n8n-nodes-base.code",
        "typeVersion": 2,
        "position": [2450, 200]
      },
      {
        "parameters": {
          "model": "{{$env.OLLAMA_EMBED_TEXT_PRIMARY}}",
          "prompt": "Repository: {{$json.repoName}}\\nFile: {{$json.relativePath}}\\nType: {{$json.fileType}}\\n\\nContent:\\n{{$json.content}}"
        },
        "id": "generate-embedding",
        "name": "Generate Embedding",
        "type": "@n8n/n8n-nodes-ollama.ollama",
        "typeVersion": 1,
        "position": [2650, 200],
        "credentials": {
          "ollamaApi": {
            "id": "{{OLLAMA_CREDENTIAL_ID}}"
          }
        }
      },
      {
        "parameters": {
          "operation": "insert",
          "collection": "documents",
          "content": "={{JSON.stringify({vectors: $json.embedding, payload: {document_id: $json.documentId, chunk_index: $json.chunkIndex, source_type: 'git', repo_name: $json.repoName, file_path: $json.relativePath, file_type: $json.fileType, chunk_type: $json.chunkType}})}}"
        },
        "id": "insert-qdrant",
        "name": "Insert to Qdrant",
        "type": "@n8n/n8n-nodes-qdrant.qdrant",
        "typeVersion": 1,
        "position": [2850, 200],
        "credentials": {
          "qdrantApi": {
            "id": "{{QDRANT_CREDENTIAL_ID}}"
          }
        }
      },
      {
        "parameters": {
          "command": "rm -rf /tmp/repo_*"
        },
        "id": "cleanup",
        "name": "Cleanup Temp Files",
        "type": "n8n-nodes-base.executeCommand",
        "typeVersion": 1,
        "position": [3050, 300]
      }
    ],
    "connections": {
      "schedule-trigger": {
        "main": [[{"node": "set-repos", "type": "main", "index": 0}]]
      },
      "set-repos": {
        "main": [[{"node": "split-repos", "type": "main", "index": 0}]]
      },
      "split-repos": {
        "main": [[{"node": "clone-repo", "type": "main", "index": 0}]]
      },
      "clone-repo": {
        "main": [[{"node": "find-files", "type": "main", "index": 0}]]
      },
      "find-files": {
        "main": [[{"node": "prepare-files", "type": "main", "index": 0}]]
      },
      "prepare-files": {
        "main": [[{"node": "batch-files", "type": "main", "index": 0}]]
      },
      "batch-files": {
        "main": [[{"node": "read-file", "type": "main", "index": 0}]]
      },
      "read-file": {
        "main": [[{"node": "process-content", "type": "main", "index": 0}]]
      },
      "process-content": {
        "main": [[{"node": "upsert-document", "type": "main", "index": 0}]]
      },
      "upsert-document": {
        "main": [[{"node": "check-if-new", "type": "main", "index": 0}]]
      },
      "check-if-new": {
        "main": [
          [{"node": "chunk-content", "type": "main", "index": 0}],
          [{"node": "batch-files", "type": "main", "index": 0}]
        ]
      },
      "chunk-content": {
        "main": [[{"node": "generate-embedding", "type": "main", "index": 0}]]
      },
      "generate-embedding": {
        "main": [[{"node": "insert-qdrant", "type": "main", "index": 0}]]
      },
      "insert-qdrant": {
        "main": [[{"node": "batch-files", "type": "main", "index": 0}]]
      },
      "batch-files": {
        "main": [[{"node": "cleanup", "type": "main", "index": 0}]]
      }
    },
    "settings": {
      "executionOrder": "v1"
    },
    "staticData": null,
    "meta": {
      "templateId": "git-ingestion"
    }
  }