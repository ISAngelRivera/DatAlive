# docker-compose.yml - DataLive RAG System v2.0
# Actualizado con mejores prácticas 2025

x-common-variables: &common-variables
  TZ: ${TZ:-Europe/Madrid}
  NODE_ENV: ${NODE_ENV:-production}

x-healthcheck-defaults: &healthcheck-defaults
  interval: 30s
  timeout: 10s
  retries: 5
  start_period: 40s

services:
  # 1. Orquestador Principal - N8N
  n8n:
    image: n8nio/n8n:latest
    container_name: datalive-n8n
    restart: unless-stopped
    user: "1000:1000"
    ports:
      - "5678:5678"
    environment:
      <<: *common-variables
      N8N_METRICS: true
      N8N_RUNNERS_ENABLED: true
      N8N_SECURE_COOKIE: false
      N8N_LOG_LEVEL: info
      N8N_VERSION_NOTIFICATIONS_ENABLED: false
      N8N_TEMPLATES_ENABLED: true
      N8N_PERSONALIZATION_ENABLED: false
      N8N_ENCRYPTION_KEY_FILE: /run/secrets/n8n_encryption_key
      DB_TYPE: postgresdb
      DB_POSTGRESDB_HOST: postgres
      DB_POSTGRESDB_PORT: 5432
      DB_POSTGRESDB_DATABASE: ${POSTGRES_DB}
      DB_POSTGRESDB_USER: ${POSTGRES_USER}
      DB_POSTGRESDB_PASSWORD: adminpassword
      EXECUTIONS_MODE: queue
      QUEUE_BULL_REDIS_HOST: redis
      QUEUE_BULL_REDIS_PORT: 6379
      QUEUE_BULL_REDIS_PASSWORD: ${REDIS_PASSWORD}
    volumes:
      - n8n_data:/home/node/.n8n
      - ./workflows:/workflows:ro
    networks:
      - frontend
      - backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      qdrant:
        condition: service_started
    secrets:
      - postgres_password
      - n8n_encryption_key
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:5678/healthz"]
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # 2. Base de Datos Principal
  postgres:
    image: postgres:16-alpine
    container_name: datalive-postgres
    restart: unless-stopped
    user: "999:999"
    ports:
      - "5432:5432"
    environment:
      <<: *common-variables
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --lc-collate=C --lc-ctype=C"
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres-init:/docker-entrypoint-initdb.d:ro
      - ./backups/postgres:/backups
    networks:
      - backend
      - frontend
    secrets:
      - postgres_password
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 1G

  # 3. Cache Redis
  redis:
    image: redis:7-alpine
    container_name: datalive-redis
    restart: unless-stopped
    user: "999:999"
    ports:
      - "6379:6379"
    command: >
      redis-server
      --requirepass "${REDIS_PASSWORD:-change_this_redis_password}"
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
    volumes:
      - redis_data:/data
    networks:
      - backend
      - frontend
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G

  # 4. Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    container_name: datalive-qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"
      - "6334:6334"
    environment:
      <<: *common-variables
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__LOG_LEVEL: INFO
    volumes:
      - qdrant_data:/qdrant/storage
      - ./config/qdrant/config.yaml:/qdrant/config/production.yaml:ro
    networks:
      - backend
      - frontend
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:6333/health"]
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G

  # 5. LLM & Embeddings Server
  ollama:
    image: ollama/ollama:latest
    container_name: datalive-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    environment:
      <<: *common-variables
      OLLAMA_MODELS: /models
      OLLAMA_HOST: 0.0.0.0
      OLLAMA_ORIGINS: "*"
      OLLAMA_MAX_LOADED_MODELS: 2
      OLLAMA_NUM_PARALLEL: 4
      OLLAMA_MAX_QUEUE: 100
    volumes:
      - ollama_models:/models
      - ./scripts/ollama-init.sh:/docker-entrypoint-initdb.d/init.sh:ro
    networks:
      - backend
      - frontend
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 16G
        reservations:
          cpus: '2'
          memory: 8G
      # Uncomment for GPU support
      # devices:
      #   - driver: nvidia
      #     count: 1
      #     capabilities: [gpu]

  # 6. Object Storage
  minio:
    image: minio/minio:latest
    container_name: datalive-minio
    restart: unless-stopped
    ports:
      - "9000:9000"  # API
      - "9001:9001"  # Console
    environment:
      <<: *common-variables
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD_FILE: /run/secrets/minio_secret_key
      MINIO_BROWSER_REDIRECT_URL: http://localhost:9001
      MINIO_PROMETHEUS_AUTH_TYPE: public
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    networks:
      - backend
      - frontend
    secrets:
      - minio_secret_key
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/ready"]
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G

  # 7. Prometheus - Métricas
  prometheus:
    image: prom/prometheus:latest
    container_name: datalive-prometheus
    restart: unless-stopped
    user: "65534:65534"
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./config/prometheus:/etc/prometheus:ro
      - prometheus_data:/prometheus
    networks:
      - backend
      - frontend
      - monitoring
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]

  # 8. Grafana - Visualización
  grafana:
    image: grafana/grafana:latest
    container_name: datalive-grafana
    restart: unless-stopped
    user: "472:472"
    ports:
      - "3000:3000"
    environment:
      <<: *common-variables
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD__FILE: /run/secrets/grafana_password
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource
      GF_USERS_ALLOW_SIGN_UP: false
      GF_ANALYTICS_REPORTING_ENABLED: false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./config/grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - frontend
      - monitoring
    depends_on:
      - prometheus
    secrets:
      - grafana_password
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]

  # 9. Loki - Logs
  loki:
    image: grafana/loki:latest
    container_name: datalive-loki
    restart: unless-stopped
    user: "10001:10001"
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/config.yml
    volumes:
      - ./config/loki/config.yml:/etc/loki/config.yml:ro
      - loki_data:/loki
    networks:
      - monitoring
      - frontend
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3100/ready"]

  # 10. Promtail - Log Collector
  promtail:
    image: grafana/promtail:latest
    container_name: datalive-promtail
    restart: unless-stopped
    command: -config.file=/etc/promtail/config.yml
    volumes:
      - ./config/promtail/config.yml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    networks:
      - monitoring
    depends_on:
      - loki

# Volúmenes
volumes:
  n8n_data:
    driver: local
  postgres_data:
    driver: local
  redis_data:
    driver: local
  qdrant_data:
    driver: local
  ollama_models:
    driver: local
  minio_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  loki_data:
    driver: local

# Redes
networks:
  frontend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/24
  backend:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.21.0.0/24
  monitoring:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.22.0.0/24

# Secrets
secrets:
  postgres_password:
    file: ./secrets/postgres_password.txt
  minio_secret_key:
    file: ./secrets/minio_secret_key.txt
  n8n_encryption_key:
    file: ./secrets/n8n_encryption_key.txt
  grafana_password:
    file: ./secrets/grafana_password.txt